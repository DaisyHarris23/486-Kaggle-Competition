{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1157adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "def extract_number(text):\n",
    "    match = re.search(r'(\\d+\\.?\\d*)', str(text))\n",
    "    if match:\n",
    "        return float(match.group())\n",
    "    else:\n",
    "        return 0.5  # if it doesn't have a number, it is 'half-bath'\n",
    "\n",
    "train['baths'] = train['bathrooms_text'].apply(extract_number)\n",
    "train['host_acceptance_rate'] = train['host_acceptance_rate'].str.rstrip('%').astype(float) / 100\n",
    "\n",
    "train['host_is_superhost'] = train['host_is_superhost'].astype('category')\n",
    "train['host_location'] = train['host_location'].astype('category')\n",
    "train['neighbourhood_cleansed'] = train['neighbourhood_cleansed'].astype('category')\n",
    "train['property_type'] = train['property_type'].astype('category')\n",
    "train['instant_bookable'] = train['instant_bookable'].astype('category')\n",
    "train['amenities'] = train['amenities'].astype('category')\n",
    "train['host_response_time'] = train['host_response_time'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4a6bf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR 10: MAE = 154.93620542791422\n",
      "SVR 1: MAE = 165.83814264073848\n",
      "SVR .1: MAE = 180.12402156311964\n",
      "XGB - base: MAE = 188.3676455633535\n",
      "XGB - best params: MAE = 189.78980538575817\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "y = train.loc[:, ['price']]\n",
    "X = train.loc[:, ['host_location', #maybe\n",
    "                  'host_response_time', #maybe\n",
    "                  'host_acceptance_rate', \n",
    "                  'host_is_superhost', \n",
    "                  'neighbourhood_cleansed', \n",
    "                  'property_type', #'room_type'?\n",
    "                  'accommodates', \n",
    "                  'baths', \n",
    "                  'beds',  #not bedrooms\n",
    "                  'amenities', # or if it even has amenities, or pools vs hottub or pets\n",
    "                  'maximum_maximum_nights', \n",
    "                  'maximum_nights',\n",
    "                  'number_of_reviews', \n",
    "                  'number_of_reviews_ltm',  #check this\n",
    "                  'instant_bookable'\n",
    "]] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=307)\n",
    "\n",
    "\n",
    "num_features = ['host_acceptance_rate', \n",
    "                'accommodates', \n",
    "                'baths', \n",
    "                'beds', \n",
    "                'maximum_maximum_nights', \n",
    "                'maximum_nights', \n",
    "                'number_of_reviews', \n",
    "                'number_of_reviews_ltm'\n",
    "               ]\n",
    "\n",
    "cat_features = ['host_response_time', \n",
    "                'host_location', \n",
    "                'host_is_superhost', \n",
    "                'neighbourhood_cleansed', \n",
    "                'property_type',\n",
    "                'amenities', \n",
    "                'instant_bookable'\n",
    "               ]\n",
    "\n",
    "\n",
    "numeric = Pipeline(steps=[('impute', SimpleImputer(strategy='median')), \n",
    "                 ('polynomial', PolynomialFeatures(degree = 2, include_bias=False)),\n",
    "                 ('standardize', StandardScaler()),\n",
    "                 ('percent', SelectPercentile(f_regression, percentile=40))])\n",
    "\n",
    "categorical = Pipeline(steps=[('impute2', SimpleImputer(strategy='most_frequent')),\n",
    "                     ('one_hot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),\n",
    "                     ('percent', SelectPercentile(f_regression, percentile=60))\n",
    "                     ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric, num_features),\n",
    "        (\"categorical\", categorical, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "#     'Random Forest': RandomForestRegressor(), #Camilla\n",
    "#     'Decision Tree Regressor': DecisionTreeRegressor(), # Daisy\n",
    "    'SVR 10': SVR(C=10), \n",
    "    'SVR 1': SVR(C=1), \n",
    "    'SVR .1': SVR(C=.1), \n",
    "    'XGB - base': XGBRegressor(),\n",
    "    'XGB - best params': XGBRegressor(colsample_bytree = 1, learning_rate=.1, max_depth=7,subsample=.9),\n",
    "#     'XGB - 1 depth 5': XGBRegressor(colsample_bytree = 1, learning_rate=.1, max_depth=5,subsample=.9),\n",
    "#     'XGB - 2 depth 9': XGBRegressor(colsample_bytree = 1, learning_rate=.1, max_depth=9,subsample=.9),\n",
    "#     'XGB - 3 sub .5': XGBRegressor(colsample_bytree = 1, learning_rate=.1, max_depth=5,subsample=.5),\n",
    "#     'XGB - 4 sub .3': XGBRegressor(colsample_bytree = 1, learning_rate=.1, max_depth=5,subsample=.3),   \n",
    "#     'XGB - 5 col .9': XGBRegressor(colsample_bytree = .9, learning_rate=.1, max_depth=5,subsample=.9),   \n",
    "#     'XGB - 6 col .7': XGBRegressor(colsample_bytree = .7, learning_rate=.1, max_depth=5,subsample=.9),\n",
    "#     'XGB - 7 - learn .01': XGBRegressor(colsample_bytree = 1, learning_rate=.01, max_depth=5,subsample=.5)   \n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Create a pipeline for each model\n",
    "pipelines = {}\n",
    "for model_name, model in models.items():\n",
    "    pipelines[model_name] = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "# Fit and evaluate each pipeline\n",
    "results = {}\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train)  # Fit the pipeline\n",
    "    y_pred = pipeline.predict(X_test)  # Make predictions\n",
    "    mae = mean_absolute_error(y_test, y_pred)  # Calculate MAE\n",
    "    results[model_name] = mae\n",
    "\n",
    "# Print results\n",
    "for model_name, mae in results.items():\n",
    "    print(f\"{model_name}: MAE = {mae}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb0545c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'xgb_regressor__colsample_bytree': 1.0, 'xgb_regressor__learning_rate': 0.1, 'xgb_regressor__max_depth': 7, 'xgb_regressor__subsample': 0.9}\n",
      "Mean Absolute Error on test set: 189.78980538575817\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "y = train.loc[:, ['price']]\n",
    "X = train.loc[:, ['host_location', #maybe\n",
    "                  'host_response_time', #maybe\n",
    "                  'host_acceptance_rate', \n",
    "                  'host_is_superhost', \n",
    "                  'neighbourhood_cleansed', \n",
    "                  'property_type', #'room_type'?\n",
    "                  'accommodates', \n",
    "                  'baths', \n",
    "                  'beds',  #not bedrooms\n",
    "                  'amenities', # or if it even has amenities, or pools vs hottub or pets\n",
    "                  'maximum_maximum_nights', \n",
    "                  'maximum_nights',\n",
    "                  'number_of_reviews', \n",
    "                  'number_of_reviews_ltm',  #check this\n",
    "                  'instant_bookable'\n",
    "]] \n",
    "\n",
    "\n",
    "num_features = ['host_acceptance_rate', \n",
    "                'accommodates', \n",
    "                'baths', \n",
    "                'beds', \n",
    "                'maximum_maximum_nights', \n",
    "                'maximum_nights', \n",
    "                'number_of_reviews', \n",
    "                'number_of_reviews_ltm'\n",
    "               ]\n",
    "\n",
    "cat_features = ['host_response_time', \n",
    "                'host_location', \n",
    "                'host_is_superhost', \n",
    "                'neighbourhood_cleansed', \n",
    "                'property_type',\n",
    "                'amenities', \n",
    "                'instant_bookable'\n",
    "               ]\n",
    "\n",
    "\n",
    "numeric = Pipeline(steps=[('impute', SimpleImputer(strategy='median')), \n",
    "                 ('polynomial', PolynomialFeatures(degree = 2, include_bias=False)),\n",
    "                 ('standardize', StandardScaler()),\n",
    "                 ('percent', SelectPercentile(f_regression, percentile=40))])\n",
    "\n",
    "categorical = Pipeline(steps=[('impute2', SimpleImputer(strategy='most_frequent')),\n",
    "                     ('one_hot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),\n",
    "                     ('percent', SelectPercentile(f_regression, percentile=60))\n",
    "                     ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric, num_features),\n",
    "        (\"categorical\", categorical, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "xgb_regressor = XGBRegressor()\n",
    "\n",
    "# Create the pipeline combining preprocessing and XGBoost model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb_regressor', xgb_regressor)\n",
    "])\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'xgb_regressor__learning_rate': [0.1, 0.01],\n",
    "    'xgb_regressor__max_depth': [3, 5, 7],\n",
    "    'xgb_regressor__subsample': [0.8, 0.9, 1.0],\n",
    "    'xgb_regressor__colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=307)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"Mean Absolute Error on test set:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4230bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bytree 1, learning rate .1, max depth 7, subsample .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80fab0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b082ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7d229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04890dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR 10: MAE = 155.98024167395775\n",
      "XGB - base: MAE = 136.38005644678094\n",
      "XGB - best params: MAE = 163.42094218602156\n"
     ]
    }
   ],
   "source": [
    "num_features = ['host_acceptance_rate', \n",
    "                'accommodates', \n",
    "                'baths', \n",
    "                'beds', \n",
    "                'maximum_maximum_nights', \n",
    "                'maximum_nights', \n",
    "                'number_of_reviews', \n",
    "#                 'number_of_reviews_ltm'\n",
    "               ]\n",
    "\n",
    "cat_features = [#'host_response_time', \n",
    "#                 'host_location', \n",
    "                'host_is_superhost', \n",
    "                'neighbourhood_cleansed', \n",
    "                'property_type',\n",
    "                'amenities', \n",
    "                'instant_bookable'\n",
    "               ]\n",
    "\n",
    "X = train.loc[:, [#'host_location', #maybe\n",
    "                  #'host_response_time', #maybe\n",
    "                  'host_acceptance_rate', \n",
    "                  'host_is_superhost', \n",
    "                  'neighbourhood_cleansed', \n",
    "                  'property_type', #'room_type'?\n",
    "                  'accommodates', \n",
    "                  'baths', \n",
    "                  'beds',  #not bedrooms\n",
    "                  'amenities', # or if it even has amenities, or pools vs hottub or pets\n",
    "                  'maximum_maximum_nights', \n",
    "                  'maximum_nights',\n",
    "                  'number_of_reviews', \n",
    "#                   'number_of_reviews_ltm',  #check this\n",
    "                  'instant_bookable'\n",
    "    ]] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=307)\n",
    "\n",
    "numeric = Pipeline(steps=[('impute', SimpleImputer(strategy='median')), \n",
    "                 ('polynomial', PolynomialFeatures(degree = 2, include_bias=False)),\n",
    "                 ('standardize', StandardScaler()),\n",
    "                 ('percent', SelectPercentile(f_regression, percentile=40))])\n",
    "\n",
    "categorical = Pipeline(steps=[('impute2', SimpleImputer(strategy='most_frequent')),\n",
    "                     ('one_hot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),\n",
    "                     ('percent', SelectPercentile(f_regression, percentile=60))\n",
    "                     ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric, num_features),\n",
    "        (\"categorical\", categorical, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "#     'Random Forest': RandomForestRegressor(), #Camilla\n",
    "#     'Decision Tree Regressor': DecisionTreeRegressor(), # Daisy\n",
    "    'SVR 10': SVR(C=10), \n",
    "#     'SVR 1': SVR(C=1), \n",
    "#     'SVR .1': SVR(C=.1), \n",
    "    'XGB - base': XGBRegressor(),\n",
    "    'XGB - best params': XGBRegressor(colsample_bytree = 1, learning_rate=.1, max_depth=7,subsample=.9),  \n",
    "}\n",
    "\n",
    "# Create a pipeline for each model\n",
    "pipelines = {}\n",
    "for model_name, model in models.items():\n",
    "    pipelines[model_name] = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "# Fit and evaluate each pipeline\n",
    "results = {}\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train)  # Fit the pipeline\n",
    "    y_pred = pipeline.predict(X_test)  # Make predictions\n",
    "    mae = mean_absolute_error(y_test, y_pred)  # Calculate MAE\n",
    "    results[model_name] = mae\n",
    "\n",
    "# Print results\n",
    "for model_name, mae in results.items():\n",
    "    print(f\"{model_name}: MAE = {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2eac28aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR 10: MAE = 125.91300706894509\n",
      "XGB - base: MAE = 115.85598036146398\n",
      "XGB - best params: MAE = 142.1385458638742\n"
     ]
    }
   ],
   "source": [
    "num_features = ['host_acceptance_rate', \n",
    "                'accommodates', \n",
    "                'baths', \n",
    "                'beds', \n",
    "#                 'maximum_maximum_nights', \n",
    "                'maximum_nights', \n",
    "                'number_of_reviews', \n",
    "#                 'number_of_reviews_ltm'\n",
    "               ]\n",
    "\n",
    "cat_features = [#'host_response_time', \n",
    "#                 'host_location', \n",
    "                'host_is_superhost', \n",
    "                'neighbourhood_cleansed', \n",
    "                'property_type',\n",
    "                'amenities', \n",
    "                'instant_bookable'\n",
    "               ]\n",
    "\n",
    "\n",
    "\n",
    "# What helps most to least in the model\n",
    "X = train.loc[:, [\n",
    "                  # USE FOR SURE\n",
    "                  'amenities', # NEEEEED THIS ONE\n",
    "                  'property_type', # 9 points\n",
    "                  'baths', # 9 points\n",
    "                  'host_acceptance_rate', # 7 points\n",
    "                  'beds',  # 6 points\n",
    "                  'neighbourhood_cleansed',  # 5 points\n",
    "                  'accommodates', # 4 points\n",
    "                  'host_is_superhost', # 1 point\n",
    "                  'instant_bookable', # .3 points\n",
    "                  'maximum_nights', # .3 points\n",
    "                  'number_of_reviews', # .3 points\n",
    "\n",
    "    \n",
    "                    # SHOULD TAKE OUT\n",
    "#                   'number_of_reviews_ltm',  # LARGE negative effect\n",
    "#                   'host_location', # medium negative effect\n",
    "#                   'host_response_time', # small negative effect\n",
    "#                   'maximum_maximum_nights', # - .2\n",
    "\n",
    "    ]] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=307)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3071)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30714)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=307149)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "numeric = Pipeline(steps=[('impute', SimpleImputer(strategy='median')), \n",
    "                 ('polynomial', PolynomialFeatures(degree = 2, include_bias=False)),\n",
    "                 ('standardize', StandardScaler()),\n",
    "                 ('percent', SelectPercentile(f_regression, percentile=40))])\n",
    "\n",
    "categorical = Pipeline(steps=[('impute2', SimpleImputer(strategy='most_frequent')),\n",
    "                     ('one_hot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),\n",
    "                     ('percent', SelectPercentile(f_regression, percentile=60))\n",
    "                     ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric, num_features),\n",
    "        (\"categorical\", categorical, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "#     'Random Forest': RandomForestRegressor(), #Camilla\n",
    "#     'Decision Tree Regressor': DecisionTreeRegressor(), # Daisy\n",
    "    'SVR 10': SVR(C=10), \n",
    "    'XGB - base': XGBRegressor(),\n",
    "    'XGB - best params': XGBRegressor(colsample_bytree = 1, learning_rate=.1, max_depth=7,subsample=.9),  \n",
    "}\n",
    "\n",
    "# Create a pipeline for each model\n",
    "pipelines = {}\n",
    "for model_name, model in models.items():\n",
    "    pipelines[model_name] = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "# Fit and evaluate each pipeline\n",
    "results = {}\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train)  # Fit the pipeline\n",
    "    y_pred = pipeline.predict(X_test)  # Make predictions\n",
    "    mae = mean_absolute_error(y_test, y_pred)  # Calculate MAE\n",
    "    results[model_name] = mae\n",
    "\n",
    "# Print results\n",
    "for model_name, mae in results.items():\n",
    "    print(f\"{model_name}: MAE = {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best 136.11702607524765\n",
    "\n",
    "# leaderboard - individual: 128.7\n",
    "\n",
    "# after trying with xgboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4424cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train1 = pd.read_csv('test.csv')\n",
    "\n",
    "def extract_number(text):\n",
    "    match = re.search(r'(\\d+\\.?\\d*)', str(text))\n",
    "    if match:\n",
    "        return float(match.group())\n",
    "    else:\n",
    "        return 0.5  # if it doesn't have a number, it is 'half-bath'\n",
    "\n",
    "train['baths'] = train['bathrooms_text'].apply(extract_number)\n",
    "train['host_acceptance_rate'] = train['host_acceptance_rate'].str.rstrip('%').astype(float) / 100\n",
    "train['host_is_superhost'] = train['host_is_superhost'].astype('category')\n",
    "train['host_location'] = train['host_location'].astype('category')\n",
    "train['neighbourhood_cleansed'] = train['neighbourhood_cleansed'].astype('category')\n",
    "train['property_type'] = train['property_type'].astype('category')\n",
    "train['instant_bookable'] = train['instant_bookable'].astype('category')\n",
    "train['amenities'] = train['amenities'].astype('category')\n",
    "train['host_response_time'] = train['host_response_time'].astype('category')\n",
    "\n",
    "\n",
    "#same for test\n",
    "train1['baths'] = train1['bathrooms_text'].apply(extract_number)\n",
    "train1['host_acceptance_rate'] = train1['host_acceptance_rate'].str.rstrip('%').astype(float) / 100\n",
    "train1['host_is_superhost'] = train1['host_is_superhost'].astype('category')\n",
    "train1['host_location'] = train1['host_location'].astype('category')\n",
    "train1['neighbourhood_cleansed'] = train1['neighbourhood_cleansed'].astype('category')\n",
    "train1['property_type'] = train1['property_type'].astype('category')\n",
    "train1['instant_bookable'] = train1['instant_bookable'].astype('category')\n",
    "train1['amenities'] = train1['amenities'].astype('category')\n",
    "train1['host_response_time'] = train1['host_response_time'].astype('category')\n",
    "\n",
    "\n",
    "numeric = Pipeline(steps=[('impute', SimpleImputer(strategy='median')), \n",
    "                 ('polynomial', PolynomialFeatures(degree = 2, include_bias=False)),\n",
    "                 ('standardize', StandardScaler()),\n",
    "                 ('percent', SelectPercentile(f_regression, percentile=40))])\n",
    "\n",
    "categorical = Pipeline(steps=[('impute2', SimpleImputer(strategy='most_frequent')),\n",
    "                     ('one_hot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),\n",
    "                     ('percent', SelectPercentile(f_regression, percentile=60))\n",
    "                     ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric, num_features),\n",
    "        (\"categorical\", categorical, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "features = train.loc[:, [\n",
    "                  # USE FOR SURE\n",
    "                  'amenities', # NEEEEED THIS ONE\n",
    "                  'property_type', # 9 points\n",
    "                  'baths', # 9 points\n",
    "                  'host_acceptance_rate', # 7 points\n",
    "                  'beds',  # 6 points\n",
    "                  'neighbourhood_cleansed',  # 5 points\n",
    "                  'accommodates', # 4 points\n",
    "                  'host_is_superhost', # 1 point\n",
    "                  'instant_bookable', # .3 points\n",
    "                  'maximum_nights', # .3 points\n",
    "                  'number_of_reviews', # .3 points\n",
    "    ]] \n",
    "\n",
    "y = train.loc[:, ['price']]\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "           (\"model\", XGBRegressor())])\n",
    "\n",
    "\n",
    "pipe.fit(features, y)\n",
    "new_y = pipe.predict(train1)\n",
    "new_y\n",
    "\n",
    "final = train1.copy()\n",
    "\n",
    "columns_to_drop = train1.columns.difference(['Id'])\n",
    "final = final.drop(columns=columns_to_drop)\n",
    "\n",
    "final['price'] = new_y\n",
    "final.to_csv('final_predictions2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
